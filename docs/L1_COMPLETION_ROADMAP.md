# L1 å±‚å®Œæˆè·¯çº¿å›¾

**å±‚çº§**: L1 ç»Ÿä¸€å†…æ ¸å±‚ï¼ˆUnified Kernelï¼‰  
**å½“å‰è¿›åº¦**: 80%  
**å‰©ä½™å·¥ä½œ**: 3 å‘¨  
**ä¼˜å…ˆçº§**: P0/P1

---

## ğŸ“‹ æ¦‚è¿°

L1 å±‚çš„æ ¸å¿ƒæ¨¡å—å·²å®Œæˆï¼Œå‰©ä½™ 3 ä¸ªå…³é”®åŠŸèƒ½éœ€è¦å®ç°ï¼š

1. **æŒ‡æ ‡å¯¼å‡ºï¼ˆMetrics Exportï¼‰** - P0 ä¼˜å…ˆçº§ï¼Œ1 å‘¨
2. **æœ€å°åŒ–é‡æ”¾ï¼ˆMinimal Replayï¼‰** - P1 ä¼˜å…ˆçº§ï¼Œ1 å‘¨
3. **å®Œæ•´å¯è§‚æµ‹æ€§é›†æˆ** - P1 ä¼˜å…ˆçº§ï¼Œ1 å‘¨

---

## âœ… å·²å®Œæˆæ¨¡å—å›é¡¾

### 1. registryï¼ˆæ³¨å†Œä¸­å¿ƒï¼‰- å®Œæˆ âœ…
- Session/Tab/Frame ç”Ÿå‘½å‘¨æœŸç®¡ç†
- å±‚çº§æ ‘ç»“æ„ç»´æŠ¤
- äº‹ä»¶è®°å½•åˆ° State Center
- çº¿ç¨‹å®‰å…¨çš„çŠ¶æ€è®¿é—®

### 2. schedulerï¼ˆè°ƒåº¦å™¨ï¼‰- å®Œæˆ âœ…
- ToolCall éªŒè¯ã€å»é‡ã€ä¼˜å…ˆçº§é˜Ÿåˆ—
- ä¸ Registry é›†æˆ
- å–æ¶ˆä»¤ç‰Œæ”¯æŒ
- CLI å‘½ä»¤ï¼š`soulbrowser scheduler`

### 3. state-centerï¼ˆçŠ¶æ€ä¸­å¿ƒï¼‰- å®Œæˆ âœ…
- Ring buffers äº‹ä»¶å­˜å‚¨
- å†å²æŸ¥è¯¢ API
- è°ƒåº¦ç»“æœè·Ÿè¸ª
- åŸºç¡€é‡æ”¾æ„å»ºå™¨ï¼ˆéœ€å®Œå–„ï¼‰

### 4. policy-centerï¼ˆç­–ç•¥ä¸­å¿ƒï¼‰- å®Œæˆ âœ…
- ç­–ç•¥é…ç½®ç®¡ç†
- è¿è¡Œæ—¶è¦†ç›–
- CLI å‘½ä»¤ï¼š`soulbrowser policy show/override`

### 5. event-busï¼ˆäº‹ä»¶æ€»çº¿ï¼‰- å®Œæˆ âœ…
- å‘å¸ƒ/è®¢é˜…æœºåˆ¶
- è·¨æ¨¡å—æ¶ˆæ¯ä¼ é€’

---

## ğŸ¯ Week 1: æŒ‡æ ‡å¯¼å‡ºç³»ç»Ÿ

### ä¼˜å…ˆçº§ï¼šP0 ğŸ”¥

### ç›®æ ‡
å®ç° Prometheus æ ¼å¼çš„æŒ‡æ ‡å¯¼å‡ºï¼Œä¸ºç”Ÿäº§ç›‘æ§æä¾›æ”¯æŒã€‚

### Day 1-2: Prometheus é›†æˆä¸æ ¸å¿ƒæŒ‡æ ‡

**ä½ç½®**: `crates/scheduler/src/metrics.rs`, `crates/registry/src/metrics.rs`

**ä»»åŠ¡æ¸…å•**:

- [x] **æ·»åŠ ä¾èµ–**
  ```toml
  [dependencies]
  prometheus = "0.13"
  lazy_static = "1.4"
  ```

- [x] **å®šä¹‰ Scheduler æŒ‡æ ‡**
  ```rust
  use prometheus::{IntCounter, IntGauge, Histogram, Registry};
  use lazy_static::lazy_static;
  
  lazy_static! {
      pub static ref SCHEDULER_QUEUE_LENGTH: IntGauge =
          IntGauge::new("scheduler_queue_length", "Current queue length").unwrap();
      
      pub static ref SCHEDULER_DISPATCHES_TOTAL: IntCounter =
          IntCounter::new("scheduler_dispatches_total", "Total dispatches").unwrap();
      
      pub static ref SCHEDULER_FAILURES_TOTAL: IntCounter =
          IntCounter::new("scheduler_failures_total", "Total failures").unwrap();
      
      pub static ref SCHEDULER_EXECUTION_DURATION: Histogram =
          Histogram::with_opts(
              HistogramOpts::new("scheduler_execution_duration_seconds", "Execution duration")
                  .buckets(vec![0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0])
          ).unwrap();
  }
  
  pub fn register_metrics(registry: &Registry) {
      registry.register(Box::new(SCHEDULER_QUEUE_LENGTH.clone())).unwrap();
      registry.register(Box::new(SCHEDULER_DISPATCHES_TOTAL.clone())).unwrap();
      registry.register(Box::new(SCHEDULER_FAILURES_TOTAL.clone())).unwrap();
      registry.register(Box::new(SCHEDULER_EXECUTION_DURATION.clone())).unwrap();
  }
  ```

- [x] **å®šä¹‰ Registry æŒ‡æ ‡**
  ```rust
  lazy_static! {
      pub static ref REGISTRY_SESSIONS_TOTAL: IntGauge =
          IntGauge::new("registry_sessions_total", "Total sessions").unwrap();
      
      pub static ref REGISTRY_PAGES_ACTIVE: IntGauge =
          IntGauge::new("registry_pages_active", "Active pages").unwrap();
      
      pub static ref REGISTRY_FRAMES_TOTAL: IntGauge =
          IntGauge::new("registry_frames_total", "Total frames").unwrap();
  }
  ```

- [x] **é›†æˆåˆ° Scheduler**
  ```rust
  impl Scheduler {
      pub async fn dispatch(&self, tool_call: ToolCall) -> Result<()> {
          // æ›´æ–°é˜Ÿåˆ—é•¿åº¦
          SCHEDULER_QUEUE_LENGTH.inc();
          
          let start = Instant::now();
          
          match self.execute_tool_call(tool_call).await {
              Ok(_) => {
                  SCHEDULER_DISPATCHES_TOTAL.inc();
              }
              Err(e) => {
                  SCHEDULER_FAILURES_TOTAL.inc();
              }
          }
          
          // è®°å½•æ‰§è¡Œæ—¶é—´
          let duration = start.elapsed().as_secs_f64();
          SCHEDULER_EXECUTION_DURATION.observe(duration);
          
          SCHEDULER_QUEUE_LENGTH.dec();
          
          Ok(())
      }
  }
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ‰€æœ‰æŒ‡æ ‡æ­£ç¡®å®šä¹‰
- âœ… æŒ‡æ ‡æ­£ç¡®æ›´æ–°
- âœ… å•å…ƒæµ‹è¯•é€šè¿‡

---

### Day 3-4: HTTP æŒ‡æ ‡ç«¯ç‚¹ + è‡ªå®šä¹‰æŒ‡æ ‡

**ä½ç½®**: `src/main.rs`, `crates/cdp-adapter/src/metrics.rs`

**ä»»åŠ¡æ¸…å•**:

- [x] **HTTP æœåŠ¡å™¨**
  ```toml
  [dependencies]
  axum = "0.7"
  tokio = { version = "1.39", features = ["full"] }
  ```

  ```rust
  use axum::{routing::get, Router};
  use prometheus::{Encoder, TextEncoder};
  
  async fn metrics_handler() -> String {
      let encoder = TextEncoder::new();
      let metric_families = prometheus::gather();
      let mut buffer = vec![];
      encoder.encode(&metric_families, &mut buffer).unwrap();
      String::from_utf8(buffer).unwrap()
  }
  
  pub async fn start_metrics_server(port: u16) {
      let app = Router::new().route("/metrics", get(metrics_handler));
      
      let addr = format!("0.0.0.0:{}", port);
      tracing::info!("Metrics server listening on {}", addr);
      
      axum::Server::bind(&addr.parse().unwrap())
          .serve(app.into_make_service())
          .await
          .unwrap();
  }
  ```

- [x] **CDP Adapter æŒ‡æ ‡**
  ```rust
  lazy_static! {
      pub static ref CDP_COMMANDS_TOTAL: IntCounterVec =
          IntCounterVec::new(
              Opts::new("cdp_commands_total", "Total CDP commands"),
              &["command"]
          ).unwrap();
      
      pub static ref CDP_COMMAND_DURATION: HistogramVec =
          HistogramVec::new(
              HistogramOpts::new("cdp_command_duration_seconds", "CDP command duration")
                  .buckets(vec![0.01, 0.05, 0.1, 0.5, 1.0, 5.0]),
              &["command"]
          ).unwrap();
      
      pub static ref CDP_RECONNECTIONS_TOTAL: IntCounter =
          IntCounter::new("cdp_reconnections_total", "Total reconnections").unwrap();
  }
  
  impl CdpAdapter {
      pub async fn send_command(&self, method: &str, params: Value) -> Result<Value> {
          let start = Instant::now();
          
          let result = self.transport.send_command(method, params).await;
          
          // è®°å½•æŒ‡æ ‡
          CDP_COMMANDS_TOTAL.with_label_values(&[method]).inc();
          CDP_COMMAND_DURATION
              .with_label_values(&[method])
              .observe(start.elapsed().as_secs_f64());
          
          result
      }
      
      pub async fn reconnect(&mut self) -> Result<()> {
          CDP_RECONNECTIONS_TOTAL.inc();
          // ... reconnect logic
      }
  }
  ```

- [x] **CLI é›†æˆ**
  ```rust
  // åœ¨ main.rs ä¸­å¯åŠ¨
  #[tokio::main]
  async fn main() {
      // ... åˆå§‹åŒ–
      
      // æ³¨å†Œæ‰€æœ‰æŒ‡æ ‡
      let registry = prometheus::Registry::new();
      scheduler::metrics::register_metrics(&registry);
      registry::metrics::register_metrics(&registry);
      cdp_adapter::metrics::register_metrics(&registry);
      
      // å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨
      tokio::spawn(async move {
          start_metrics_server(9090).await;
      });
      
      // ... ä¸»é€»è¾‘
  }
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… HTTP ç«¯ç‚¹ `/metrics` å¯è®¿é—®
- âœ… æ‰€æœ‰æŒ‡æ ‡æ­£ç¡®å¯¼å‡º
- âœ… Prometheus å¯æ­£ç¡®æŠ“å–

---

### Day 5: æ€§èƒ½åŸºçº¿ä¸åŸºå‡†æµ‹è¯•

**ä½ç½®**: `benches/scheduler_bench.rs`

**ä»»åŠ¡æ¸…å•**:

- [ ] **æ·»åŠ  Criterion**
  ```toml
  [dev-dependencies]
  criterion = "0.5"
  
  [[bench]]
  name = "scheduler_bench"
  harness = false
  ```

- [ ] **è°ƒåº¦å™¨åŸºå‡†æµ‹è¯•**
  ```rust
  use criterion::{black_box, criterion_group, criterion_main, Criterion};
  
  fn scheduler_dispatch_benchmark(c: &mut Criterion) {
      let rt = tokio::runtime::Runtime::new().unwrap();
      let scheduler = rt.block_on(async {
          Scheduler::new().await
      });
      
      c.bench_function("scheduler_dispatch", |b| {
          b.to_async(&rt).iter(|| async {
              let tool_call = ToolCall {
                  id: "test".to_string(),
                  tool: "navigate".to_string(),
                  params: json!({ "url": "https://example.com" }),
              };
              scheduler.dispatch(black_box(tool_call)).await.unwrap();
          });
      });
  }
  
  criterion_group!(benches, scheduler_dispatch_benchmark);
  criterion_main!(benches);
  ```

- [ ] **è¿è¡ŒåŸºå‡†æµ‹è¯•**
  ```bash
  cargo bench
  
  # ç”ŸæˆæŠ¥å‘Š
  open target/criterion/report/index.html
  ```

- [ ] **è®°å½•åŸºçº¿**
  ```markdown
  ## Performance Baseline (2025-01-21)
  
  ### Scheduler
  - dispatch: 45Î¼s (P50), 120Î¼s (P95), 250Î¼s (P99)
  - queue_length: 0-100 ç¨³å®š
  
  ### Registry
  - resolve_route: 5Î¼s (P50), 15Î¼s (P95)
  
  ### CDP Adapter
  - navigate: 450ms (P50), 850ms (P95)
  - click: 85ms (P50), 180ms (P95)
  - type_text: 120ms (P50), 250ms (P95)
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… åŸºå‡†æµ‹è¯•å¯é‡å¤è¿è¡Œ
- âœ… æ€§èƒ½åŸºçº¿å·²è®°å½•
- âœ… P95/P99 åœ¨å¯æ¥å—èŒƒå›´

---

## ğŸ¯ Week 2: æœ€å°åŒ–é‡æ”¾åŠŸèƒ½

### ä¼˜å…ˆçº§ï¼šP1

### ç›®æ ‡
ä» State Center æå–äº‹ä»¶ï¼Œç”Ÿæˆå¯é‡æ”¾çš„æ—¶é—´çº¿ï¼Œç”¨äºé—®é¢˜è¯Šæ–­å’Œè°ƒè¯•ã€‚

### Day 1-2: é‡æ”¾æ•°æ®ç»“æ„

**ä½ç½®**: `crates/state-center/src/replay.rs`

**ä»»åŠ¡æ¸…å•**:

- [ ] **é‡æ”¾æ•°æ®ç»“æ„**
  ```rust
  use serde::{Serialize, Deserialize};
  use chrono::{DateTime, Utc};
  
  #[derive(Debug, Serialize, Deserialize)]
  pub struct ReplayTimeline {
      pub session_id: String,
      pub started_at: DateTime<Utc>,
      pub finished_at: DateTime<Utc>,
      pub events: Vec<ReplayEvent>,
      pub metadata: ReplayMetadata,
  }
  
  #[derive(Debug, Serialize, Deserialize)]
  pub struct ReplayEvent {
      pub offset_ms: u64,  // ç›¸å¯¹ started_at çš„åç§»
      pub event_type: String,
      pub data: serde_json::Value,
  }
  
  #[derive(Debug, Serialize, Deserialize)]
  pub struct ReplayMetadata {
      pub tool_calls: Vec<String>,
      pub pages_visited: Vec<String>,
      pub errors: Vec<String>,
      pub total_duration_ms: u64,
  }
  ```

- [ ] **åºåˆ—åŒ–æ ¼å¼**
  ```toml
  [dependencies]
  bincode = "1.3"
  flate2 = "1.0"
  ```

  ```rust
  pub fn serialize_timeline(timeline: &ReplayTimeline) -> Result<Vec<u8>> {
      use flate2::write::GzEncoder;
      use flate2::Compression;
      
      // å…ˆç”¨ bincode åºåˆ—åŒ–
      let encoded = bincode::serialize(timeline)?;
      
      // å†ç”¨ gzip å‹ç¼©
      let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
      std::io::Write::write_all(&mut encoder, &encoded)?;
      let compressed = encoder.finish()?;
      
      Ok(compressed)
  }
  
  pub fn deserialize_timeline(data: &[u8]) -> Result<ReplayTimeline> {
      use flate2::read::GzDecoder;
      
      // è§£å‹
      let mut decoder = GzDecoder::new(data);
      let mut decompressed = Vec::new();
      std::io::Read::read_to_end(&mut decoder, &mut decompressed)?;
      
      // ååºåˆ—åŒ–
      let timeline: ReplayTimeline = bincode::deserialize(&decompressed)?;
      Ok(timeline)
  }
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… æ•°æ®ç»“æ„å®šä¹‰å®Œæ•´
- âœ… åºåˆ—åŒ–/ååºåˆ—åŒ–æ­£ç¡®
- âœ… å‹ç¼©ç‡ > 50%

---

### Day 3-4: é‡æ”¾æ„å»ºå™¨

**ä½ç½®**: `crates/state-center/src/replay.rs`

**ä»»åŠ¡æ¸…å•**:

- [ ] **é‡æ”¾æ„å»ºå™¨**
  ```rust
  pub struct ReplayBuilder {
      state_center: Arc<StateCenter>,
  }
  
  impl ReplayBuilder {
      pub async fn build_timeline(
          &self,
          session_id: &str,
      ) -> Result<ReplayTimeline> {
          // æå–æ‰€æœ‰äº‹ä»¶
          let events = self.state_center.query_history(EventFilter {
              session_id: Some(session_id.to_string()),
              ..Default::default()
          }).await?;
          
          if events.is_empty() {
              return Err(ReplayError::NoEvents);
          }
          
          // è®¡ç®—æ—¶é—´åç§»
          let started_at = events[0].timestamp;
          let finished_at = events.last().unwrap().timestamp;
          
          let replay_events: Vec<ReplayEvent> = events.iter()
              .filter(|e| self.should_include(e))  // è¿‡æ»¤å™ªéŸ³
              .map(|e| ReplayEvent {
                  offset_ms: (e.timestamp - started_at).num_milliseconds() as u64,
                  event_type: e.event_type.clone(),
                  data: self.sanitize_data(&e.data),  // è„±æ•
              })
              .collect();
          
          // ç”Ÿæˆå…ƒæ•°æ®
          let metadata = self.build_metadata(&events);
          
          Ok(ReplayTimeline {
              session_id: session_id.to_string(),
              started_at,
              finished_at,
              events: replay_events,
              metadata,
          })
      }
      
      fn should_include(&self, event: &StateEvent) -> bool {
          // è¿‡æ»¤è§„åˆ™
          match event.event_type.as_str() {
              "HEARTBEAT" => false,  // è·³è¿‡å¿ƒè·³
              "METRICS" => false,    // è·³è¿‡æŒ‡æ ‡
              _ => true,
          }
      }
      
      fn sanitize_data(&self, data: &Value) -> Value {
          // è„±æ•å¤„ç†
          let mut sanitized = data.clone();
          
          // ç§»é™¤æ•æ„Ÿå­—æ®µ
          if let Some(obj) = sanitized.as_object_mut() {
              obj.remove("password");
              obj.remove("token");
              obj.remove("cookie");
              
              // URL æŸ¥è¯¢å‚æ•°æ‰“ç 
              if let Some(url) = obj.get_mut("url") {
                  if let Some(url_str) = url.as_str() {
                      *url = json!(redact_url_params(url_str));
                  }
              }
          }
          
          sanitized
      }
      
      fn build_metadata(&self, events: &[StateEvent]) -> ReplayMetadata {
          let mut tool_calls = Vec::new();
          let mut pages_visited = Vec::new();
          let mut errors = Vec::new();
          
          for event in events {
              match event.event_type.as_str() {
                  "DISPATCH_STARTED" => {
                      if let Some(tool) = event.data.get("tool") {
                          tool_calls.push(tool.as_str().unwrap().to_string());
                      }
                  }
                  "PAGE_LOADED" => {
                      if let Some(url) = event.data.get("url") {
                          pages_visited.push(url.as_str().unwrap().to_string());
                      }
                  }
                  "DISPATCH_FAILED" => {
                      if let Some(error) = event.data.get("error") {
                          errors.push(error.as_str().unwrap().to_string());
                      }
                  }
                  _ => {}
              }
          }
          
          let total_duration_ms = if events.len() > 1 {
              (events.last().unwrap().timestamp - events[0].timestamp)
                  .num_milliseconds() as u64
          } else {
              0
          };
          
          ReplayMetadata {
              tool_calls,
              pages_visited,
              errors,
              total_duration_ms,
          }
      }
  }
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… äº‹ä»¶æ­£ç¡®æå–
- âœ… å™ªéŸ³æ­£ç¡®è¿‡æ»¤
- âœ… æ•æ„Ÿæ•°æ®è„±æ•
- âœ… å…ƒæ•°æ®æ­£ç¡®ç”Ÿæˆ

---

### Day 5: CLI å‘½ä»¤é›†æˆ

**ä½ç½®**: `src/main.rs`

**ä»»åŠ¡æ¸…å•**:

- [ ] **å¯¼å‡ºå‘½ä»¤**
  ```rust
  #[derive(Parser)]
  #[command(name = "replay")]
  #[command(about = "Replay management")]
  struct ReplayArgs {
      #[command(subcommand)]
      command: ReplayCommand,
  }
  
  #[derive(Subcommand)]
  enum ReplayCommand {
      Export {
          session_id: String,
          #[arg(short, long)]
          output: Option<PathBuf>,
      },
      View {
          replay_file: PathBuf,
      },
  }
  
  async fn handle_replay_command(args: ReplayArgs) -> Result<()> {
      match args.command {
          ReplayCommand::Export { session_id, output } => {
              let builder = ReplayBuilder::new(state_center);
              let timeline = builder.build_timeline(&session_id).await?;
              
              let data = serialize_timeline(&timeline)?;
              
              let output_path = output.unwrap_or_else(|| {
                  PathBuf::from(format!("replay_{}.bin.gz", session_id))
              });
              
              std::fs::write(&output_path, data)?;
              println!("Replay exported to: {}", output_path.display());
              
              Ok(())
          }
          ReplayCommand::View { replay_file } => {
              let data = std::fs::read(&replay_file)?;
              let timeline = deserialize_timeline(&data)?;
              
              println!("Session ID: {}", timeline.session_id);
              println!("Started at: {}", timeline.started_at);
              println!("Duration: {}ms", timeline.metadata.total_duration_ms);
              println!("\nTool Calls:");
              for tool in &timeline.metadata.tool_calls {
                  println!("  - {}", tool);
              }
              println!("\nPages Visited:");
              for url in &timeline.metadata.pages_visited {
                  println!("  - {}", url);
              }
              println!("\nEvents: {}", timeline.events.len());
              
              for event in timeline.events.iter().take(10) {
                  println!("  [{:6}ms] {}", event.offset_ms, event.event_type);
              }
              
              Ok(())
          }
      }
  }
  ```

- [ ] **ä½¿ç”¨ç¤ºä¾‹**
  ```bash
  # å¯¼å‡ºé‡æ”¾
  soulbrowser replay export abc123 --output session.replay
  
  # æŸ¥çœ‹é‡æ”¾
  soulbrowser replay view session.replay
  
  # è¾“å‡º:
  # Session ID: abc123
  # Started at: 2025-01-21 10:30:00 UTC
  # Duration: 45230ms
  # 
  # Tool Calls:
  #   - navigate
  #   - click
  #   - type_text
  # 
  # Pages Visited:
  #   - https://example.com
  #   - https://example.com/login
  # 
  # Events: 156
  #   [     0ms] DISPATCH_STARTED
  #   [   450ms] PAGE_LOADED
  #   [  1200ms] DISPATCH_FINISHED
  #   ...
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… CLI å‘½ä»¤æ­£å¸¸å·¥ä½œ
- âœ… å¯¼å‡ºæ–‡ä»¶å¯è¯»å–
- âœ… æŸ¥çœ‹è¾“å‡ºå‹å¥½

---

## ğŸ¯ Week 3: å®Œæ•´å¯è§‚æµ‹æ€§é›†æˆ

### ä¼˜å…ˆçº§ï¼šP1

### ç›®æ ‡
é›†æˆ tracingï¼Œå®ç°ç»“æ„åŒ–æ—¥å¿—å’Œå¯é€‰çš„å¤–éƒ¨å¯¼å‡ºã€‚

### Day 1-2: Tracing é›†æˆ

**ä½ç½®**: å…¨å±€é›†æˆ

**ä»»åŠ¡æ¸…å•**:

- [x] **æ·»åŠ ä¾èµ–**
  ```toml
  [dependencies]
  tracing = "0.1"
  tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }
  tracing-appender = "0.2"
  ```

- [ ] **åˆå§‹åŒ– tracing**
  ```rust
  use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};
  
  fn init_tracing() {
      tracing_subscriber::registry()
          .with(EnvFilter::from_default_env()
              .add_directive("soulbrowser=debug".parse().unwrap()))
          .with(tracing_subscriber::fmt::layer()
              .with_target(true)
              .with_thread_ids(true))
          .init();
  }
  ```

- [ ] **Span è®¾è®¡**
  ```rust
  // Session span
  #[instrument(name = "session", skip(self), fields(session_id = %session_id))]
  pub async fn create_session(&self) -> SessionId {
      let session_id = SessionId::new();
      tracing::info!("Session created");
      session_id
  }
  
  // Page span
  #[instrument(name = "page", parent = session_span, fields(page_id = %page_id))]
  pub async fn create_page(&self, session_id: SessionId) -> PageId {
      let page_id = PageId::new();
      tracing::info!("Page created");
      page_id
  }
  
  // Action span
  #[instrument(name = "action", skip(self), fields(action_id = %ctx.action_id, tool = %tool_name))]
  pub async fn execute_action(&self, ctx: &ExecCtx, tool_name: &str) -> Result<ActionReport> {
      tracing::debug!("Action started");
      // ...
      tracing::info!(latency_ms = %report.latency_ms, "Action finished");
      Ok(report)
  }
  
  // Primitive span
  #[instrument(name = "primitive", parent = action_span, fields(primitive = "click"))]
  pub async fn click(&self, ctx: &ExecCtx, anchor: &AnchorDescriptor) -> Result<ActionReport> {
      tracing::trace!("Click primitive executing");
      // ...
  }
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… Tracing æ­£ç¡®åˆå§‹åŒ–
- âœ… Span å±‚çº§æ­£ç¡®
- âœ… Context ä¼ æ’­æ­£å¸¸

---

### Day 3-4: ç»“æ„åŒ–æ—¥å¿—

**ä½ç½®**: å…¨å±€

**ä»»åŠ¡æ¸…å•**:

- [ ] **JSON æ ¼å¼æ—¥å¿—**
  ```rust
  fn init_json_logging() {
      let file_appender = tracing_appender::rolling::daily("logs", "soulbrowser.log");
      let (non_blocking, _guard) = tracing_appender::non_blocking(file_appender);
      
      tracing_subscriber::registry()
          .with(EnvFilter::from_default_env())
          .with(
              tracing_subscriber::fmt::layer()
                  .json()
                  .with_writer(non_blocking)
          )
          .init();
  }
  ```

- [ ] **æ•æ„Ÿæ•°æ®è„±æ•**
  ```rust
  use tracing::field::{Field, Visit};
  
  struct SanitizingVisitor;
  
  impl Visit for SanitizingVisitor {
      fn record_str(&mut self, field: &Field, value: &str) {
          let sanitized = match field.name() {
              "password" | "token" | "cookie" => "***REDACTED***",
              "url" => redact_url_params(value),
              _ => value,
          };
          // ... è®°å½•
      }
  }
  ```

- [ ] **æ—¥å¿—è½®è½¬é…ç½®**
  ```rust
  // æŒ‰å¤§å°è½®è½¬
  let file_appender = tracing_appender::rolling::RollingFileAppender::new(
      tracing_appender::rolling::Rotation::DAILY,
      "logs",
      "soulbrowser.log",
  );
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… JSON æ—¥å¿—æ ¼å¼æ­£ç¡®
- âœ… æ•æ„Ÿæ•°æ®è„±æ•
- âœ… æ—¥å¿—è½®è½¬æ­£å¸¸

---

### Day 5: å¯é€‰çš„å¤–éƒ¨å¯¼å‡º

**ä½ç½®**: `src/observability.rs`

**ä»»åŠ¡æ¸…å•**:

- [ ] **Jaeger Exporterï¼ˆå¯é€‰ï¼‰**
  ```toml
  [dependencies]
  opentelemetry = { version = "0.21", optional = true }
  opentelemetry-jaeger = { version = "0.20", optional = true }
  tracing-opentelemetry = { version = "0.22", optional = true }
  
  [features]
  jaeger = ["opentelemetry", "opentelemetry-jaeger", "tracing-opentelemetry"]
  ```

  ```rust
  #[cfg(feature = "jaeger")]
  fn init_jaeger() -> Result<()> {
      use opentelemetry::global;
      use opentelemetry_jaeger::Exporter;
      
      let tracer = Exporter::builder()
          .with_agent_endpoint("localhost:6831")
          .init()?;
      
      global::set_tracer_provider(tracer);
      
      Ok(())
  }
  ```

**éªŒæ”¶æ ‡å‡†**:
- âœ… Feature flag æ­£å¸¸å·¥ä½œ
- âœ… Jaeger å¯æ­£ç¡®æ¥æ”¶

---

## ï¿½ï¿½ éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- âœ… æŒ‡æ ‡å¯¼å‡ºæ”¯æŒ Prometheus æ ¼å¼
- âœ… HTTP `/metrics` ç«¯ç‚¹å¯è®¿é—®
- âœ… é‡æ”¾åŠŸèƒ½å¯ç”Ÿæˆå®Œæ•´æ—¶é—´çº¿
- âœ… CLI å‘½ä»¤å…¨éƒ¨å¯ç”¨
- âœ… æ‰€æœ‰æ¨¡å—æœ‰ tracing span
- âœ… ç»“æ„åŒ–æ—¥å¿—æ­£ç¡®è¾“å‡º

### æ€§èƒ½éªŒæ”¶
- âœ… æŒ‡æ ‡æ›´æ–°å¼€é”€ < 1Î¼s
- âœ… é‡æ”¾ç”Ÿæˆæ—¶é—´ < 1sï¼ˆ1000 äº‹ä»¶ï¼‰
- âœ… æ—¥å¿—å†™å…¥ä¸é˜»å¡ä¸»çº¿ç¨‹

### è´¨é‡éªŒæ”¶
- âœ… å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- âœ… é›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡
- âœ… æ–‡æ¡£å®Œæ•´

---

## ğŸš€ äº¤ä»˜ç‰©

### Week 1 äº¤ä»˜
- Prometheus æŒ‡æ ‡å¯¼å‡ºç³»ç»Ÿ
- HTTP `/metrics` ç«¯ç‚¹
- æ€§èƒ½åŸºçº¿æŠ¥å‘Š

### Week 2 äº¤ä»˜
- é‡æ”¾æ•°æ®ç»“æ„ä¸åºåˆ—åŒ–
- CLI `replay export/view` å‘½ä»¤
- é‡æ”¾ç¤ºä¾‹æ–‡ä»¶

### Week 3 äº¤ä»˜
- Tracing é›†æˆ
- ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ
- å¯è§‚æµ‹æ€§æ–‡æ¡£

---

**æ–‡æ¡£ç»´æŠ¤**: æ¯å‘¨æ›´æ–°è¿›åº¦ã€‚
